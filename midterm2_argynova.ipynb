{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from mnist import MNIST\n",
    "from keras.datasets import mnist\n",
    "import random\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "#index = random.randrange(0, len(x_train))  # choose an index\n",
    "#print('The amount of train images', len(x_train))\n",
    "#print('The amount of test images', len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "Train on 6000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 30s 5ms/step - loss: 1.0209 - acc: 0.6793 - val_loss: 0.4297 - val_acc: 0.8680\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 27s 5ms/step - loss: 0.4713 - acc: 0.8583 - val_loss: 0.3356 - val_acc: 0.8910\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 27s 5ms/step - loss: 0.3738 - acc: 0.8878 - val_loss: 0.3148 - val_acc: 0.8920\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.3290 - acc: 0.8998 - val_loss: 0.2517 - val_acc: 0.9170\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.2830 - acc: 0.9130 - val_loss: 0.2075 - val_acc: 0.9290\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.2467 - acc: 0.9255 - val_loss: 0.1860 - val_acc: 0.9390\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 27s 5ms/step - loss: 0.2164 - acc: 0.9360 - val_loss: 0.1695 - val_acc: 0.9430\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 29s 5ms/step - loss: 0.1905 - acc: 0.9420 - val_loss: 0.1645 - val_acc: 0.9400\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.1755 - acc: 0.9458 - val_loss: 0.1479 - val_acc: 0.9510\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 28s 5ms/step - loss: 0.1573 - acc: 0.9545 - val_loss: 0.1308 - val_acc: 0.9600\n",
      "[0.12560410420345142, 0.96179999999999999]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.00001, verbose=1),\n",
    "]\n",
    "\n",
    "#seed = 7\n",
    "#numpy.random.seed(seed)\n",
    "\n",
    "#input_dim = x_train[0].shape[0]*x_train[0].shape[1]\n",
    "#print((x_train[0].shape[0],x_train[0].shape[1]))\n",
    "#print(y_train.shape)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "x_train = (x_train.astype('float32'))/255\n",
    "x_test =  (x_test.astype('float32'))/255\n",
    "print(x_train.shape)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 6000 samples & 10000 tests\n",
    "model.fit(x_train[0:6000], y_train[0:6000], batch_size = 10, epochs = 10, verbose = 1, validation_data=(x_test[0:1000], y_test[0:1000]), callbacks = callbacks)\n",
    "\n",
    "results = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
